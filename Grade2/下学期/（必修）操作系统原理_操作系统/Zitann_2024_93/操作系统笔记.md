# 第一章 操作系统引论

## 操作系统的基本特性

- **==并发性==：进程：**两个或两个以上的事件在同一时间段内发生
  - **意义：**系统中程序能并发执行的特征，使得OS能有效**提高**系统资源**利用率**，**增加系统吞吐量**
  - **引入进程**：引入之前，属于同一个应用程序的计算程序和I/O程序之间只能是**顺序执行**，即只有在计算程序执行告一段落后，才允许I/O程序执行；反之，在程序执行I/O操作时，计算程序也不能执行。**引入进程**后，可以为计算程序和I/O程序分别建立一个进程(Process)后，这两个进程便可**并发执行**
  - **并行性**是指两个或多个事件在**同一时刻发生**
  - **在多道程序环境下，**并发性**是指宏观上在**一段时间内**有多道程序在**同时执行**。但在单处理机系统中，每一个时刻仅能执行一道程序，故微观上，这些程序是在**交互执行**
- **==共享性==：资源：**计算机系统中的资源能够被并发执行的多个进程共同使用
  - **意义：**共享是指系统中的所有资源不再为一个程序所独占，而是供同时存在于系统中的多道程序所共同使用。根据资源属性不同，可有互斥共享和同时共享两种不同的共享方式。
  - **互斥共享**：在一段时间内，只允许一个进程访问该资源。统中应建立一种机制以保证多个进程对这类资源的互斥访问
  - **同时共享：**允许在一段时间内由多个进程“同时” 进行访问。这里所谓的“同时”，在单处理机环境下是宏观意义上的，而在微观上，这些进程对该资源的访问是交替进行的。典型的可供多个进程“同时”访问的资源是磁盘设备。一些用重入码编写的文件也可以被“同时”共享，即允许若干个用户同时访问该文件
- **==虚拟性==：存储：**系统通过某种技术将一个实际存在的实体变成多个逻辑上的对应体
  - **意义：**指通过某种技术把一个物理实体变成若是个逻辑上的对应物。物理实体是实际存在的；逻辑物体是用户感觉到的，是虚拟的。例如在单CPU多道分时系统中，通过多道程序技术和分时技术可以把一个物理CPU虚拟为多台逻辑上的CPU，使每个终端用户都认为有一台“独立”的CPU为它运行，用户感觉的CPU是虚拟CPU。
  - **时分复用技术**：多道程序设计和一台处理机，分时为多个用户使用，从而实现一台物理处理机被虚拟成多个逻辑处理机。
  - **空分复用技术**：利用存储器的空闲空间分区域存放和运行其他的多道程序，以此提高内存的利用率。
- **==异步性==：进程：**也称为随机性，是指多道程序环境中多个进程的执行、推进和完成时间都是随机、交替、不可预测的
  - **意义：**在多道程序环境下，允许多个程序并发执行，但由于资源等因素的限制，程序的执行并非“一气呵成”，而是以“走走停停”的方式运行，即程序是以异步方式运行的。 
  - 在单处理机环境下，由于系统中只有一台处理机，因而每次只允许一个进程执行，其余进程只能等待。
  - 当正在执行的进程提出某种资源要求时，如打印请求，而此时打印机正在为其它进程打印，由于打印机属于临界资源，因此正在执行的进程必须等待，并释放出处理机，直到打印机空闲，并再次获得处理机时，该进程方能继续执行。

> **并发和共享关系：**并发和共享是操作系统的两个最基本的特性，它们又是互为存在条件。一方面资源共享是以程序（进程）的并发性执行为条件的，若系统不允许程序并发执行，自然不存在资源共享问题。另一方面若系统不能对资源共享实施有效管理，则也必将影响到程序并发执行。

> **不确定性（nondeterministic）：**每个程序（进程）执行速度和时间不确定，各程序（进程）之间推进序列也不确定。即是不可预测的；每个程序（进程）执行结果不确定，即对同一程序，给定相同的初始条件、在相同的环境下进行多次执行，却可能获得完全不同的结果，这也称为程序并发执行的不可再现性。执行结果的不确定性是绝对不允许的，这是操作系统为实现程序并发执行必须解决的问题。

## 分时系统的特征

- 分时系统实现中的**关键问题**：
  - **及时接收：**及时接收用户的命令或数据，解决的办法是配置**多路卡**
  - **及时处理：**及时处理用户命令，应该使所有的用户的作业都直接进入**内存**；在很短的时间内使每个作业都运行一次
- 多用户分时、前台和后台程序分时、时间片分配、抢先式、非抢先式
- **==多路性==：**允许在一台主机上同时联接多台联机终端，系统按分时原则为每个用户服务。宏观上是多个用户同时工作，共享系统资源，而微观上则是每个用户作业轮流运行一个时间片。多路性即同时性，它提高了资源利用率，从而促进了计算机更广泛的应用。
- **==独立性==：**每个用户各占一个终端，彼此独立操作，互不干扰。因此用户会感觉到就象他一人独占主机。
- **==交互性==：**用户可通过终端与系统进行广泛的人机对话。用户可以请求系统提供多方面服务，如文件编辑，数据处理和资源共享等。
- **==及时性==：**用户的请求能在很短时间内获得响应，此时间间隔是以人们所能接受的等待时间来确定的，通常为1-2秒。
- **==时间片轮转==**

## 线程的实现方式

### 线程的基本概念

- 线程是进程的一部分，描述指令流执行状态，它是进程中==指令执行的最小单元==，是==CPU调度的基本单位==
- **线程的优点：**一个进程中可以同时存在多个线程、各个线程间可以并发执行、各个线程之间可以共享地址空间和文件等资源
- **线程的缺点：**一个线程崩溃，会导致所属进程的所有其他线程崩溃
- **进程的两个基本属性**
  - 资源的拥有者：进程还是资源的拥有者
  - CPU调度单位：线程继承了这个属性
- **线程与进程的比较**
  - 调度的基本单位：线程作为调度和分派的基本单位
  - 并发性：引入线程的OS并发度更高
  - 拥有资源：线程本身不拥有系统资源，仅有一点必不可少的资源
  - 独立性：线程之间独立性低，共享进程的内存地址空间和资源
  - 系统开销：线程的开销低
  - 支持多处理机系统：线程更适合多处理机
- **线程和进程的关系**
  - 一个线程只能属于一个进程，而一个进程可以有多个线程，至少有一个线程。
  - 资源分配给进程，同一进程的所有线程共享该进程的所有资源。
  - 处理机分给线程，即真正在处理机上运行的是线程。
  - 线程在执行过程中，需要协作同步。不同进程的线程间要利用消息通信的办法实现同步。线程是指进程内的一个执行单元，也是进程内的可调度实体
- **线程和进程的区别**
  - 调度：线程作为调度和分配的基本单位，进程作为拥有资源的基本单位
  - 并发性：不仅进程之间可以并发执行，同一个进程的多个线程之间也可并发执行
  - 拥有资源：进程是拥有资源的一个独立单位，线程不拥有系统资源，但可以访问隶属于进程的资源
  - 系统开销：在创建或撤消进程时，由于系统都要为之分配和回收资源，导致系统的开销明显大于创建或撤消线程时的开销
- **线程的三个运行状态：**执行状态、就绪状态、阻塞状态
- **线程控制块TCB：**线程标识符、一组寄存器、线程运行状态、优先级、线程专有存储区、信号屏蔽、堆栈指针
- **多线程OS中的进程属性：**进程是一个可拥有资源的基本单位、多个线程可并发执行、进程已不是可执行的实体

### 线程的实现

- **用户级线程ULT(User level Threads)**  *UNIX*
  - 在用户空间建立线程库：提供一组管理线程的过程
  - 运行时系统：完成线程的管理工作(操作、线程表)
  - 内核管理的还是进程：内核不知道线程的存在
  - 线程切换不需要内核态特权
  - 优点
    - 线程切换不需转换到内核空间，节省了模式切换的开销
    - 调度算法是应用程序特定的
    - 用户级线程可运行在任何操作系统上（只要实现了线程库）
  - 缺点
    - 内核只将处理器分配给进程，同一进程中的两个线程不能同时运行在两个处理器上
    - 大多数系统调用是阻塞的，因此，由于内核阻塞进程，故进程中的所有线程也被阻塞

![image-20240611204552261](D:\MarkDown\assets\image-20240611204552261.png)

- **内核支持线程KST(Kernel Supported Threads)**  *Windows*
  - 内核管理所有线程管理，并向应用程序提供API
  - 内核维护进程和线程的上下文
  - 线程的切换需要内核支持
  - 以线程为基础进行调度
  - 优点
    - 在多处理器系统中，内核能够同时调度同一进程中的多个线程并行执行
    - 如果进程中一个线程被阻塞，并不会同时阻塞同一进程中的其他线程
    - 具有很小的数据结构和堆栈，线程的切换比较快
    - 内核本身也可以采用多线程技术，提高执行速度和效率
  - 缺点
    - 模式切换开销较大

![image-20240611204610521](D:\MarkDown\assets\image-20240611204610521.png)

- **组合方式**  *Solaris*
  - 线程创建在用户空间完成
  - 线程调度等在核心态完成
  - 一对一：为每一个用户线程都设置一个内核控制线程与之连接，当一个线程阻塞时，允许调度另一个线程运行。并行能力较强，但开销较大，因此需要限制整个系统的线程数（Windows2000/NT等）
  - 多对一：将多个用户线程映射到一个内核控制线程，为了管理方便，这些用户线程一般属于一个进程，运行在该进程的用户空间，对这些线程的调度和管理也是在该进程的用户空间中完成。线程管理的开销小效率高，但当一个线程在访问内核时发生阻塞，整个进程都会被阻塞；在多处理机系统中，一个进程的多个线程无法实现并行。
  - 多对多：结合上述两种模型的优点，将多个用户线程映射到多个内核控制线程，内核控制线程的数目可以根据应用进程和系统的不同而变化，可以比用户线程少，也可以与之相同。

![image-20240611204831417](D:\MarkDown\assets\image-20240611204831417.png)

![image-20240611204705339](D:\MarkDown\assets\image-20240611204705339.png)

## 同步机制应该遵循的规则

- ==空闲让进==：当无进程在互斥区时，任何有权使用互斥区的进程可进入
- ==忙则等待==：不允许两个以上的进程同时进入互斥区
- ==有限等待==：任何进入互斥区的要求应在有限的时间内得到满足
- ==让权等待==：处于等待状态的进程应放弃占用CPU，以使其他进程有机会得到CPU的使用权

## 并发执行的程序可能的运行结果

- 间断性制约：资源共享致使并发执行的程序形成相互制约的关系
- 并发程序：执行-->暂停-->执行
- 失去封闭性：资源共享导致运行失去封闭性、程序等待
- 不可再现性： 计算结果与并发程序的执行速度有关

## 前趋图，用信号量实现前趋图

### **前趋图（Precedence Graph）：描述程序执行先后顺序**

- 描述多个进程之间的关系
- 有向无循环图（DAG）
- 结点表示一个进程或一段程序
- 结点之间用一个有方向的线段相连
- 方向表示所连接的结点之间的前趋和后继关系
- 被指向的结点为后继结点，离开箭头的结点是前趋结点

### 整型信号量实现进程前趋图

通过共享一个公用信号量S，并赋 予初值为0，实现进程之间的前驱关系

![image-20240613002556603](D:\MarkDown\assets\image-20240613002556603.png)

## 整型信号量和信号量集之间的内部区别

## 整型信号量实现信号量集

## 抢占调度的原则

![image-20240613111824748](D:\MarkDown\assets\image-20240613111824748.png)

## CPU调度算法，以及每种算法的特性

### 作业与作业调度

- **作业**

  - 作业由一组统一管理和操作的进程集合构成，是用户要求计算机系统完成的一项相对独立的工作。

  - 作业可以是完成了编译、链接之后的用户程序，也可以是用各种命令构成的一个脚本

  - 作业通过相应输入设备输入到磁盘存储器，保存在后备队列（外存），由作业调度程序调入内存

  - 输入作业流：若干作业进入系统后，被依次存放在外存上

  - 处理作业流：在操作系统的控制下，逐个作业进行处理
  - 分类：根据需要处理工作的类型，分为计算型和I/O型作业，按照作业提交方式，分为批处理作业和终端型作业
  - 一个系统能够接纳作业的个数称为系统的==多道程序度==

- **作业控制块 JCB**

- **作业状态：**后备状态（收容）、运行状态、完成状态

- **==先来先服务调度算法（First-Come First-Served, FCFS）==**

  - 既可用于作业调度，也可用于进程调度。
  - 每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。
  - 有利于长作业(进程)，而不利于短作业(进程)
  - 有利于 CPU 繁忙型的作业，而不利于 I/O 繁忙型的作业。

  ![image-20240611214324907](D:\MarkDown\assets\image-20240611214324907.png)

- **==短作业/进程优先 (Short Job/Process First, SJF/SPF)==**

  - 对短作业或短进程优先调度的算法
  - 从后备队列中选择一个或若干个估计运行时间最短的作业，将它们调入内存运行
  - **必须预知作业的运行时间**：很难估计，一般会偏长估计
  - 该对长作业不利，长作业的周转时间会明显增长，甚至出现**饥饿现象**
  - 完全**未考虑作业紧迫程度**，不能保证紧迫性作业(进程)会被及时处理
  - 人机**无法实现交互**

  ![image-20240611214609957](D:\MarkDown\assets\image-20240611214609957.png)

- **==优先级调度算法 (Priority-Sheduling Algorithm, PSA)==**

  - 基于作业的紧迫程度，由外部赋予作业响应的优先级

- **==高响应比优先 (Highest Response Ratio Next, HRRN)==**

  - $$
    \text{优先权}=\frac{\text{等待时间+要求服务时间}}{\text{要求服务时间}}=\frac{\text{响应时间}}{\text{要求服务时间}}
    $$

  - 既照顾了短作业，又考虑了作业到达的先后次序，不会使长作业长期得不到服务，该算法实现了一种较好的折衷。

  - 在利用该算法时，每进行调度之前，都须先做响应比的计算，这会增加系统开销。

### 进程调度

> 进程调度 = 低级调度 = 短程调度（操作最频繁的调度）

- **进程调度的任务**

  - 保存处理机的现场信息：如程序计数器、多个通用寄存器内容等
  - 按某种算法选取进程：按某种算法从就绪队列中选取一个进程改为运行状态，并准备把处理机分配给它。
  - 把处理器分配给进程：由分派程序(Dispatcher)把处理器分配给进程，恢复处理机现场，把选中进程的PCB内有关处理机现场的信息装入处理器相应寄存器中，把处理器的控制权交给该进程，让它从取出的断点处继续运行

- **进程调度的机制**

  - 排队器：事先将系统中所有的就绪进程按照一定的方式排成一个或多个队列，以便调度程序能最快地找到它
  - 分派器(分派程序)：把由进程调度程序所选定的进程，从就绪队列中取出进行上下文切换，将处理机分配给它
  - 上下文切换器：两对上下文切换操作，1）保存当前进程的上下文，而装入分派程序的上下文，以便分派程序运行；2）将移出分派程序，而把新选进程的CPU 现场信息装入到处理机的各个相应寄存器中。

- **进程调度方式**

  - 非抢占方式 (Nonpreemptive Mode)
    - 一旦把处理机分配给某进程后，让它一直运行下去，直至该进程完成，或发生某事件而被阻塞时，才再把处理机分配给其他进程。
    - 优点：实现简单，系统开销小，适用于大多数的批处理系统环境
    - 缺点：难以满足紧急任务的要求——立即执行
  - 抢占方式 (Preemptive Mode)
    - 允许调度程序根据某种原则去暂停某个正在执行的进程，将已分配给该进程的处理机重新分配给另一进程。
    - 优点：防止长进程长时间占用处理机，为大多数进程提供更公平的服务，能满足对响应时间有着较严格要求的实时任务的需求。
    - 缺点：比非抢占方式调度所需付出的开销较大。
    - **原则：优先权原则、短作业(进程)优先原则、时间片原则**

- ==**轮转调度算法 TRR/RR**==

  - 分时思想；
  - 就绪队列按照FCFS形成;
  - 当进程运行的时间片到时，强迫进程放弃处理器，到就绪队列中再次排队，并将处理器的下一个时间片分配给就绪队列中队首的进程;
  - 时间片的大小对系统性能有很大的影响，时间片过小：频繁发生中断、进程切换，增加系统的开销；时间片过大：使得每个进程都能在一个时间片内完成，时间片轮转算法便退化为 FCFS 算法，无法满足交互式用户的需求。

  ![image-20240611215742042](D:\MarkDown\assets\image-20240611215742042.png)

- ==**优先级调度算法 PSA**==

  - 静态优先级（保持不变）
  - 动态优先级（随时间改变）

  ![image-20240611220006406](D:\MarkDown\assets\image-20240611220006406.png)

- **==多队列调度算法==**

  - 处理器将就绪队列拆分为若干个，将不同类型或性质的进程固定分配在不同的就绪队列，采用不同调度算法

  ![image-20240611220210848](D:\MarkDown\assets\image-20240611220210848.png)

- **==多级反馈队列调度算法==**

  - 设置多个就绪队列，并为各个队列赋予不同的优先级，第一个队列的优先级最高，优先权愈高的队列中，时间片愈小
  - 每个队列都采用FCFS算法

  ![image-20240611220105641](D:\MarkDown\assets\image-20240611220105641.png)

- **基于公平原则的调度算法**

  - 保证调度算法：向用户所做出的保证并不是优先运行，而是明确的性能保证，该算法可以做到调度的公平性。
  - 公平分享调度算法：调度的公平性主要针对用户而言，使所有用户能获得相同的处理机时间，或所要求的时间比例;


### 实时调度

- **类型：**HRT——硬实时、SRT——软实**时**
- **基本条件：**提供必要信息、系统处理能力强、采用抢占式调度机制、具有快速切换机制
- **系统向调度程序提供的必要信息：**就绪时间、开始截止时间、完成截止时间、处理时间、资源要求、优先级
- **实时调度算法的分类**
  - ![image-20240611220853189](D:\MarkDown\assets\image-20240611220853189.png)
  - ![image-20240611220908148](D:\MarkDown\assets\image-20240611220908148.png)
- **最早截止时间优先 (Earliest Deadline First, EDF)**
  - 根据任务的开始截止时间来确定任务的优先级，截止时间愈早，其优先级愈高，非抢占式调度方式用于非周期实时任务，抢占式调度方式用于周期实时任务
  - ![image-20240611221109925](D:\MarkDown\assets\image-20240611221109925.png)
  - ![image-20240611221209417](D:\MarkDown\assets\image-20240611221209417.png)
- **最低松弛度优先(Least Laxity First, LLF)算法**
  - 松弛程度 = 必须完成时间 - 其本身的运行时间 - 当前时间

## 处理死锁问题的方法

### 预防死锁

- 破坏“请求和保持”条件：资源一次性分配--破坏请求和保持条件
  - 优点：简单、易于实现、安全
  - 缺点：资源严重浪费，进程延迟运行，使进程经常发生饥饿现象
- 破坏“不可抢占”条件：可剥夺资源--即当某进程新的资源未满足时，释放已占有的资源，破坏不可剥夺条件
  - 优点：进程可更快完成任务、提高设备利用率、减少进程饥饿的机率
  - 缺点：实施复杂、代价大，反复申请和释放资源使进程的执行无限地推迟，延长了进程的周转时间，增加了系统开销，降低了系统吞吐量
- 破坏“循环等待”条件：资源有序分配法--系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反，破坏环路等待条件
  - 优点：资源利用率和系统吞吐量提高
  - 缺点：资源序号必须相对稳定，新设备类型增加难，进程使用资源的顺序与系统规定的顺序不同造成资源浪费限制用户简单、自主编程.

### 避免死锁

> 安全状态
>
> - 只要系统始终处于安全状态，便可避免死锁
> - 系统资源分配前先计算系统安全性，若此次分配不会导致系统进入不安全状态，便将资源分配给进程，否则进程等待

> 安全序列
>
> 一个进程序列<P1，P2，…，Pn>是安全的，如果对于每一个进程Pi(1≤i≤n），它以后尚需要的资源量不超过系统当前剩余资源量与所有进程Pj (j<i )当前占有资源量之和，系统处于安全状态

==**利用银行家算法避免死锁**==

- **银行家算法中的数据结构**
  - Available：可利用资源向量
  - Max：最大需求矩阵
  - Allocation：分配矩阵
  - Need：需求矩阵

![image-20240611223234197](D:\MarkDown\assets\image-20240611223234197.png)

![image-20240611223324912](D:\MarkDown\assets\image-20240611223324912.png)

![image-20240611223338067](D:\MarkDown\assets\image-20240611223338067.png)

### 死锁的检测与解除

- **死锁的检测**
  - 资源分配图
  - 死锁定理
  - 死锁检测中的数据结构
- **死锁的解除**
  - 利用资源抢占
  - 利用回退释放资源
  - 利用结束死锁进程释放资源

![image-20240611223822557](D:\MarkDown\assets\image-20240611223822557.png)

![image-20240611223904451](D:\MarkDown\assets\image-20240611223904451.png)

# 

## 死锁的4个必要条件

- ==互斥条件==：指进程对所分配到的资源进行排它性使用，即在一段时间内某资源只由一个进程占用
- ==请求和保持条件==：指进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源又已被其它进程占有，此时请求进程阻塞，但又对自己已获得的其它资源保持不放
- ==不剥夺条件==：指进程已获得的资源，在未使用完之前，不能被剥夺，只能在使用完时由自己释放。
- ==循环等待条件==：发生死锁时必然存在进程资源的环形链

## 银行家算法，原理、实现

> 安全状态
>
> - 只要系统始终处于安全状态，便可避免死锁
> - 系统资源分配前先计算系统安全性，若此次分配不会导致系统进入不安全状态，便将资源分配给进程，否则进程等待

> 安全序列
>
> 一个进程序列<P1，P2，…，Pn>是安全的，如果对于每一个进程Pi(1≤i≤n），它以后尚需要的资源量不超过系统当前剩余资源量与所有进程Pj (j<i )当前占有资源量之和，系统处于安全状态

==**利用银行家算法避免死锁**==

- **银行家算法中的数据结构**
  - Available：可利用资源向量
  - Max：最大需求矩阵
  - Allocation：分配矩阵
  - Need：需求矩阵

![image-20240611223234197](D:\MarkDown\assets\image-20240611223234197.png)

![image-20240611223324912](D:\MarkDown\assets\image-20240611223324912.png)

![image-20240611223338067](D:\MarkDown\assets\image-20240611223338067.png)

## 程序的链接方式

**程序的链接：**将编译或汇编后的一组目标模块及它们所需库函数装配成一个完整的装入模块

- ==静态链接static linking==：将几个目标模块链接成一个完整的装配模块，要运行时直接装入内存。由两步完成：对相对地址修改（0——L，0——L+M）；变换外部调用符号（call B —— JSR L）。（简单）
- ==装入时动态链接==：将几个目标模块边装入边链接，若发生外部调用，将引起装入程序去找出相应的外部目标模块，将它装入内存。（便于软件版本的修改和更新、便于实现目标模块的共享）
- ==运行时动态链接==：将几个目标模块边运行边链接，若没有运行的模块不在链接。（节约内存、程序运行效率更高）

## 顺序搜索的动态分区算法

- **动态/可变分区分配**

  - 在系统运行的过程中建立分区，并使分区的大小刚好与作业的大小相等；
  - 可解决固定分区严重浪费内存的问题，是一种较为实用的存储管理方法；
  - 需要解决的问题：分区分配中所用的数据结构；分区分配的算法；分区的分配和回收操作。

  ![image-20240612005419632](D:\MarkDown\assets\image-20240612005419632.png)

  - **分配算法**
    - 在采用分区存储管理的系统中，系统初启后，除操作系统占用一个分区外，其余存储区为一个大的空闲区；
    - 分区的分配是指系统根据用户的请求，在空闲区表或空闲区队列中寻找一个满足用户要求的空闲区，把这个空闲区分配给用户；
    - 以空闲区表为例，当用户要求一个大小为SIZE的存储空间时，系统查询空闲区表，找一个大于或等于SIZE的空闲区。
  - **分割策略**
    - 策略一：从空闲区的上部开始划出SIZE大小的空闲区给用户；
    - 策略二：从空闲区的底部开始向上划出SIZE大小的空闲区给用户。
    - 一般常采用第二种办法，因为这样划分时，余下的部分在空闲区表中的首地址不变，只需要修改大小即可。
  - **分配内存**
    ![image-20240612005623919](D:\MarkDown\assets\image-20240612005623919.png)
  - **内存回收**
    - 回收区与插入点的前一个空闲分区 F1相邻接：将回收区与插入点的前一分区合并，不必为回收分区分配新表项，而只需修改其前一分区 F1的大小
    - 回收分区与插入点的后一空闲分区 F2相邻接：将两分区合并，形成新的空闲分区，用回收区的首址作为新空闲区的首址，大小为两者之和。
    - 回收区同时与插入点的前、后两个分区邻接：将三个分区合并， 使用 F1的表项和 F1的首址，取消 F2的表项，大小为三者之和。
    - 回收区既不与 F1邻接，又不与 F2邻接：这时应为回收区单独建立一新表项，填写回收区的首址和大小，并根据其首址插入到空闲链中的适当位置。

- ==**首次适应（first fit, FF）算法**==

  - 分配
    - 要求空闲分区链以地址递增的次序链接
    - 当进程申请大小为SIZE的内存时，系统从空闲区表的第一个表目开始查询，直到首次找到等于或大于SIZE的空闲区；
    - 从该区中划出大小为SIZE的分区分配给进程；
    - 余下的部分仍作为一个空闲区留在空闲区表中，但要修改其首址和大小。
  - 回收：按释放区的首址，查询空闲区表；
    - 若有与释放区相邻的空闲区，则合并到相邻的空闲区中，并修改该区的大小和首址；
    - 否则，把释放区作为一个空闲区，将其大小和首址按照首地址大小递增的顺序插入到空闲区表的适当位置。
  - 排序
    - 每次分配和回收后空闲区表或空闲区队列都要按首址递增的次序排序
  - 优点
    - 释放某一存储区时，若与空闲区相邻则合并到相邻空闲分区中去，这种情况并不改变该区在表中的位置，只要修改其大小或首址。
    - 这种算法是尽可能地利用低地址空间，从而保证高地址空间有较大的空闲区。
  - 缺点
    - 低址部分不断被划分，会留下许多难以利用的、很小的空闲分区——碎片
    - 每次查找又都是从低址部分开始，会增加查找可用空闲分区时的开销

- **==循环首次适应（next fit, NF）算法==**

  - 分配
    - 在为进程分配内存空间时，从上次找到的空闲分区的下一个空闲分区开始查找，直至找到一个能满足要求的空闲分区，从中划出一块与请求大小相等的内存空间分配给作业。
    - 设置起始查寻指针，用于指示下一次起始查寻的空闲分区。
    - 采用循环查找方式，即如果最后一个(链尾)空闲分区的大小仍不能满足要求，则应返回到第一个空闲分区，比较其大小是否满足要求。
  - 回收
    - 按释放区的首址，查询空闲区表；若有与释放区相邻的空闲区，则合并到相邻的空闲区中，并修改该区的大小和首址；
    - 否则把释放区作为空闲区，将其大小和首址按照首地址大小递增的顺序插入空闲区表适当位置。
  - 优缺点
    - 内存中的空闲分区分布得更均匀，减少了查找空闲分区时的开销
    - 缺乏大的空闲分区

- **==最佳适应（best fit, BF）算法==**

  - 分配
    - 当进程申请一个存储区时，系统从表头开始查找，当找到第一个满足要求的空闲区时，停止查找，并且这个空闲区是最佳的空闲区。
    - 所谓“最佳”是指每次为作业分配内存时，总是把能满足要求、又是最小的空闲分区分配给作业，避免“大材小用”。
  - 排序
    - 将所有的空闲分区按其容量以从小到大的顺序形成一空闲分区链。
  - 优点
    - 在系统中若存在一个与申请分区大小相等的空闲区，必定会被选中，而首次适应法则不一定。
    - 若系统中不存在与申请分区大小相等的空闲区，则选中的空闲区是满足要求的最小空闲区，而不致于毁掉较大的空闲区。
  - 缺点
    - 空闲区的大小一般与申请分区大小不相等，因此将其一分为二，留下来的空闲区一般情况下是很小的，以致无法使用；
    - 随着时间的推移，系统中的小空闲区（碎片）会越来越多，从而造成存储区的大量浪费。

- **==最坏适应（worst fit, WF）算法==**

  - 分配
    - 扫描整个空闲分区表或链表，总是挑选一个最大的空闲区分割给作业使用
    - 空闲分区按容量从大到小的顺序形成一空闲分区链
    - 查找时只要检查空闲区表的第一个空闲区的大小是否大于或等于SIZE；若空闲区小于SIZE，则分配失败；否则从空闲区中分配SIZE的存储区给用户，修改和调整空闲区表。
  - 回收
    - 按释放区的首址，查询空闲区表（队列） ，若有与释放区相邻的空闲区，合并到相邻的空闲区中，修改该区的大小和首址；否则把释放区作为空闲区插入空闲区表（队列） ；
    - 分配和回收后要对空闲区表（队列）重新排序。
  - 优缺点
    - 当程序装入内存中最大的空闲区后，剩下的空闲区还可能相当大，还能装下较大的程序；
    - 可使剩下的空闲区不至于太小，产生碎片的几率最小，对中、小作业有利；
    - 分配算法查找效率很高，每次仅作一次查询工作。
    - 但是，会使存储器中缺乏大的空闲分区

- ==**快速适应（quick fit）算法 = 分类搜索法**==

  - 分配
    - 将空闲分区根据其容量大小进行分类，对于每一类具有相同容量的所有空闲分区，单独设立一个空闲分区链表，系统中存在多个空闲分区链表
    - 在内存中设立一张管理索引表，表的每一个表项对应了一种空闲分区类型， 并记录了该类型空闲分区链表表头的指针
    - 空闲分区分类根据进程常用的空间大小进行划分
  - 优点
    - 查找效率高，仅需要根据进程长度，寻找能容纳的最小空闲区链表，并取下第一块进行分配即可
    - 进行空闲分区分配时不对任何分区产生分割，能保留大分区，满足大空间需求，不会产生碎片
  - 缺点
    - 分区归还主存时算法复杂，系统开销较大。
    - 分区以进程为单位，一个分区只属于一个进程，存在一定的浪费。
    - 空闲分区划分越细，浪费则越严重，会造成存储空间浪费，即以空间换时间

- **==伙伴系统（buddy system）==**

  - 分配
    - 无论已分配分区或空闲分区，其大小均为 2 的 k 次幂，k 为整数，l≤k≤m。假设系统的可利用空间容量为 2^m个字，则系统开始运行时，整个内存区是一个大小为 2^m 的空闲分区。
    - 在系统运行过程中，不断的划分会形成若干个不连续的空闲分区， 将这些空闲分区根据分区的大小进行分类，对于每一类具有相同大小的所有空闲分区，单独设立一个空闲分区双向链表。
    - 当需要为进程分配一个长度为 n 的存储空间时，首先计算一个 i 值，使2^(i－1)<n≤2^i，然后在空闲分区大小为 2i 的空闲分区链表中查找。若2i 的空闲分区已耗尽，则在2i＋1空闲分区链表中寻找。
    - 若存在 2i＋1的空闲分区，则把该空闲分区分为相等的两个分区，这两个分区称为一对伙伴，其中的一个分区用于分配，而把另一个加入分区大小为 2i 的空闲分区链表中。
  - 回收
    - 一次分配可能要进行多次分割一样，一次回收也可能要进行多次合并
    - 如回收大小为 2i的空闲分区时，若事先已存在 2i的空闲分区时，则应将其与伙伴分区合并为大小为 2i＋1的空闲分区，若事先已存在 2i＋1的空闲分区时，又应继续与其伙伴分区合并为大小为 2i＋2的空闲分区，依此类推。
  - 优缺点
    - 分配和回收的时间性能取决于查找空闲分区的位置和分割、合并空闲分区所花费的时间。
    - 回收空闲分区时，需要对空闲分区进行合并，所以其时间性能比快速适应算法差，但由于它采用索引搜索算法，比顺序搜索算法好。
    - 空间性能优于快速适应算法，比顺序搜索法略差
    - 在多处理机系统中，伙伴系统仍不失为一种有效的内存分配和释放的方法，得到了大量的应用

- **==哈希算法==**

  - 分配
    - 哈希算法利用哈希快速查找的优点，以及空闲分区在可利用空闲区表中的分布规律，建立哈希函数，构造一张以空闲分区大小为关键字的哈希表，该表的每一个表项纪录了一个对应的空闲分区链表表头指针。
    - 根据所需空闲分区大小，通过哈希函数计算得到在哈希表中的位置，从中得到相应的空闲分区链表，实现最佳分配策略。

- **碎片问题：**由于空闲区的大小与申请内存的大小相等的情况是很少的，绝大多数情况是从一个空闲区中切去一块，剩下的部分作为一个空闲区仍留在空闲区表中，随着时间的推移，空闲区的发展趋势是越来越小，直至不能满足任何用户要求。这种不能被任何用户使用的极小的空闲区称为碎片。碎片的出现造成了存储空间的浪费。

- **解决策略**

  - **规定门限值**（由操作系统规定，如1K），分割空闲区时，若剩余部分小于门限值，则不再分割此空闲区。
  - **定期压缩存储空间**，将所有空闲区集中到内存的一端，但这种方法的系统开销太大。

- **紧凑：**

- 将内存中的所有作业进行移动，使它们全都相邻接，把原来分散的多个小分区拼接成一个大分区

  ![image-20240612011744633](D:\MarkDown\assets\image-20240612011744633.png)

- **动态可重定位分区分配**

  - **动态重定位：**在动态运行时装入的方式中，将相对地址转换为物理地址的工作，被推迟到程序指令要真正执行时进行。当系统对内存进行了“紧凑”而使若干程序从内存的某处移至另一处时，不需对程序做任何修改，只要用该程序在内存的新起始地址，去置换原来的起始地址即可。
  - 与动态分区分配算法基本相同，差别仅在于：在这种分配算法中，增加了紧凑的功能。

  ![image-20240612012023146](D:\MarkDown\assets\image-20240612012023146.png)

## 页式、段式、段页式内存分配的原理、逻辑地址的组成、优缺点

### 分页存储管理方式

- **页面：**分页存储管理将进程的逻辑地址空间分成若干个页，并为页面加以编号，从0开始编制页号，如第0页、第1页等，页内地址是相对于0编址。

- **页面大小**

  - 在分页系统中的页面其大小应适中，且页面大小应是 2 的幂，通常为1 KB～8 KB
  - 页面若太小，一方面虽然可使内存碎片减小，从而减少了内存碎片的总空间，有利于提高内存利用率，但另一方面也会使每个进程占用较多的页面，从而导致进程的页表过长，占用大量内存；此外，还会降低页面换进换出的效率。
  - 页面较大，可以减少页表长度，提高页面换进换出速度，但又会使页内碎片增大。

- **地址结构**

  - 高位部分为页号 P，低位部分为位移量 W(或称为页内地址)。
  - 若地址长度为 32 位，其中 0～11 位为页内地址，即每页的大小为 4 KB；12～31 位为页号，地址空间最多允许有 1 M 页。

- **页地址映射：**逻辑地址A；页大小L；页号：P＝INT（A/L）页内地址：d＝A mod L

- **页表**

  - 在分页系统中，允许将进程的各个页离散地存储在内存不同的物理块中，但系统应能保证进程的正确运行，即能在内存中找到每个页面所对应的物理块。
  - 系统为每个进程建立了一张页面映像表，简称页表。在进程地址空间内的所有页(0～n)，依次在页表中有一页表项，其中记录了相应页在内存中对应的物理块号
  - 进程执行时，通过查找该表，即可找到每页在内存中的物理块号。
  - 页表的作用是实现从页号到物理块号的地址映射。

  **![image-20240612141620038](D:\MarkDown\assets\image-20240612141620038.png)**

- **地址变换机构**

  - 将用户地址空间中的逻辑地址变换为内存空间中的物理地址
  - 地址变换机构的任务：将逻辑地址中的页号，转换为内存中的物理块号。

- **基本的地址变换机构**

  - 页表的功能可以由一组专门的寄存器来实现，一个页表项用一个寄存器。页表大多驻留在内存中，在系统中只设置一个页表寄存器 PTR(Page-Table Register)，在其中存放页表在内存的始址和页表的长度。当调度程序调度到某进程时，才将这两个数据装入页表寄存器中。在单处理机环境下，虽然系统中可以运行多个进程，但只需一个页表寄存器。
  - 越界保护：在执行检索之前，先将页号与页表长度进行比较，如果页号大于或等于页表长度，则表示本次所访问的地址已超越进程的地址空间，产生地址越界中断。

  ![image-20240612142045109](D:\MarkDown\assets\image-20240612142045109.png)

- **具有快表的地址变换机构**

  - 由于页表是存放在内存中的，这使 CPU 在每存取一个数据时，都要两次访问内存：第一次是访问页表从中找到指定页的物理块号，再将块号与页内偏移量 W 拼接，以形成物理地址；第二次访问时，才是从第一次所得地址中获得所需数据(或向此地址中写入数据)。
  - 为了提高地址变换速度，可在地址变换机构中增设一个具有并行查寻能力的特殊高速缓冲寄存器，又称为联想寄存器/快表，用以存放当前访问的那些页表项

  ![image-20240612142231503](D:\MarkDown\assets\image-20240612142231503.png)

- **内存的有效访问时间**

  - 进程发出指定逻辑地址的访问请求，经过地址变换，到在内存中找到对应的实际物理地址单元并取出数据，所需花费总时间
  - 在引入块表的分页存储管理方式中，可减少一次内存访问时间，但存在找到所需表项的命中率
  - 令m为查找块表所需时间，a为命中率，t为内存访问时加，其有效访问时间：$EAT = a*m+(t+m)*(1-a)+t = 2t + m – t * a$

- **两级和多级页表**

- **反置页表**

- **优点：**便于多道程序设计，提高了内存的利用率，而不必像动态分区分配那样执行紧凑操作。

- **缺点**

  - 采用动态地址映射会增加计算机成本和降低处理机的速度。
  - 各种表格要占用一定容量的内存空间，还要花费一部分处理机时间来建立和管理这些表格。
  - 虽然消除了大量碎片，但每个作业的最后一页一般都有不能充分利用的空白区；减少页面大小，可以减少内存的浪费，但页表的长度又增加了，这也是一个矛盾。
  - 存储扩充问题仍未得到解决，当没有足够空间装下整个作业地址空间时，该作业仍无法运行。

### 分段存储管理方式

- 引入分段存储管理方式的目的：满足用户(程序员)在编程和使用上多方面的要求
- 每个段可有其逻辑意义及功能
  - 方便编程：程序更直观，更具可读性
  - 分段信息共享：段可以是信息的逻辑单位，可简化共享的实现
  - 分段信息保护：一般以一个进程、函数或文件为基本单位进行保护，更有效方便
  - 动态增长：如数据段的动态增长
  - 动态链接：动态链接要求以目标程序（即段）作为链接基本单位
- **分段：**作业的地址空间被划分为若干个段，每个段定义了一组逻辑信息，并有自己的名字和对应的段号。每个都从0开始编址，采用一段连续的地址空间。段的长度由相应的逻辑信息组的长度决定。整个作业的地址空间由于是分成多个段，因而是二维的，亦即，其逻辑地址由段号(段名)和段内地址所组成。
- **段表：**实现从逻辑段到物理内存区的映射为每个分段分配一个连续的分区，进程中的各个段可以离散地移入内存中不同的分区中。为每个进程建立一张 “段表”。每个段在表中占一个表项，记录了该段在内存中的起始地址(基址)和段的长度
- **地址变换机构：**系统中设置了段表寄存器，用于存放段表始址和段表长度TL。在进行地址变换时，系统将逻辑地址中的段号与段表长度TL进行比较。若S>TL，表示段号太大，是访问越界，于是产生越界中断信号；若未越界，则根据段表的始址和该段的段号，计算出该段对应段表项的位置，从中读出该段在内存的起始地址，然后，再检查段内地址d是否超过该段的段长SL。若超过，即d>SL，同样发出越界中断信号；若未越界，则将该段的基址d 与段内地址相加，即可得到要访问的内存物理地址。
  ![image-20240612143154170](D:\MarkDown\assets\image-20240612143154170.png)
- **分页和分段的主要区别**
  - 页是信息的物理单位，分页是为实现离散分配方式，以消减内存的外零头，提高内存的利用率。或者说，分页仅仅是由于系统管理的需要而不是用户的需要。
  - 段则是信息的逻辑单位，它含有一组其意义相对完整的信息。分段的目的是为了能更好地满足用户的需要。
  - 页的大小固定且由系统决定，由系统把逻辑地址划分为页号和页内地址两部分，是由机器硬件实现的，因而在系统中只能有一种大小的页面；
  - 而段的长度却不固定，决定于用户所编写的程序，通常由编译程序在对源程序进行编译时，根据信息的性质来划分。
  - 分页的作业地址空间是一维的，即单一的线性地址空间，程序员只需利用一个记忆符，即可表示一个地址；
  - 分段的作业地址空间则是二维的，程序员在标识一个地址时，既需给出段名，又需给出段内地址。
  - **分段系统的一个突出优点，是易于实现段的共享，即允许若干个进程共享一个或多个分段，且对段的保护也十分简单易行。**

### 段页式存储管理方式

分段和分页原理的结合，即先将用户程序分成若干个段，再把每个段分成若干个页，并为每一个段赋予一个段名
![image-20240612143446496](D:\MarkDown\assets\image-20240612143446496.png)

![image-20240612143512959](D:\MarkDown\assets\image-20240612143512959.png)
**地址变换过程：**配置一个段表寄存器，存放段表始址和段表长TL。首先用段号S与段表长TL进行比较。若S<TL，利用段表始址和段号来求出该段所对应的段表项在段表中的位置，得到该段的页表始址，并利用逻辑地址中的段内页号P 来获得对应页的页表项位置，得到物理块号b，再用块号b和页内地址来构成物理地址

![image-20240612143609222](D:\MarkDown\assets\image-20240612143609222.png)

## 缺页中断，有效访问时间

**缺页中断机构：**当所要访问的页面不在内存时，产生缺页中断，请求OS将所缺之页调入内存。

**访问内存的有效时间**

- 被访问页在内存中，且其对应的页表项在快表中：此时不存在缺页中断情况，内存的有效访问时间(EAT)分为查找快表的时间(λ)和访问实际物理地址所需的时间(t)：$EAT=\lambda+t$
- 被访问页在内存中，且其对应的页表项不在快表中：此时也不存在缺页中断情况，但需要两次访问内存，一次读取页表，一次读取数据，另外还需要更新快表。$EAT=λ+t+λ+t=2*(λ+t)$
- 被访问页不在内存中：被访问页不在内存中，需要进行缺页中断处理。假设缺页中断处理时间为ε，则$EAT=λ+t+ε+λ+t=ε+2(λ+t)$

命中率 a
缺页率 f
查找快表的时间 λ
访问实际物理地址所需的时间 t
缺页中断处理时间为 ε
EAT = λ + a*t + (1-a) * [ t + f * ( ε + λ + t ) + ( 1 – f )( λ + t )]

## 常规存储器管理方式的特征

- **单一连续分配**

  - 将内存分为两个区：
    - 系统区：仅提供给操作系统使用，可以停留在内存的低址部分，也可以在高址部分。
    - 用户区：系统区外的全部内存空间，仅装一道用户程序，即整个内存的用户区由该程序独占。
  - 操作系统和用户程序共享运行内存，只能用于单用户/任务操作系统中
  - 除嵌入式系统外，其他的计算机不再使用这种方式

  ![image-20240612001602960](D:\MarkDown\assets\image-20240612001602960.png)

- **固定分区分配**

  - 将内存空间划分为若干个固定大小的区域，称为分区。
  - 将用户可使用内存区划分为固定大小，根据作业长度分配内存；在每个区域中放入一道作业，允许放入几道作业。
  - 当有一个分区空闲时，便可从外存后备队列中选择一个适当大小的作业装入。支持多道程序的大型机使用，目前几乎不再使用

  ![image-20240612001659596](D:\MarkDown\assets\image-20240612001659596.png)

- **动态/可变分区分配**

  - 在系统运行的过程中建立分区，并使分区的大小刚好与作业的大小相等；
  - 可解决固定分区严重浪费内存的问题，是一种较为实用的存储管理方法；
  - 需要解决的问题：分区分配中所用的数据结构；分区分配的算法；分区的分配和回收操作。

  ![image-20240612005419632](D:\MarkDown\assets\image-20240612005419632.png)

  - **分配算法**
    - 在采用分区存储管理的系统中，系统初启后，除操作系统占用一个分区外，其余存储区为一个大的空闲区；
    - 分区的分配是指系统根据用户的请求，在空闲区表或空闲区队列中寻找一个满足用户要求的空闲区，把这个空闲区分配给用户；
    - 以空闲区表为例，当用户要求一个大小为SIZE的存储空间时，系统查询空闲区表，找一个大于或等于SIZE的空闲区。
  - **分割策略**
    - 策略一：从空闲区的上部开始划出SIZE大小的空闲区给用户；
    - 策略二：从空闲区的底部开始向上划出SIZE大小的空闲区给用户。
    - 一般常采用第二种办法，因为这样划分时，余下的部分在空闲区表中的首地址不变，只需要修改大小即可。
  - **分配内存**
    ![image-20240612005623919](D:\MarkDown\assets\image-20240612005623919.png)
  - **内存回收**
    - 回收区与插入点的前一个空闲分区 F1相邻接：将回收区与插入点的前一分区合并，不必为回收分区分配新表项，而只需修改其前一分区 F1的大小
    - 回收分区与插入点的后一空闲分区 F2相邻接：将两分区合并，形成新的空闲分区，用回收区的首址作为新空闲区的首址，大小为两者之和。
    - 回收区同时与插入点的前、后两个分区邻接：将三个分区合并， 使用 F1的表项和 F1的首址，取消 F2的表项，大小为三者之和。
    - 回收区既不与 F1邻接，又不与 F2邻接：这时应为回收区单独建立一新表项，填写回收区的首址和大小，并根据其首址插入到空闲链中的适当位置。

## I/O软件的层次结构

 - **用户层I/O软件：**实现与用户交互的接口，用户可直接调用在用户层提供的、与 I/O 操作有关的库函数，对设备进行操作。
 - 设备独立性软件：负责实现与设备驱动器的统一接口、设备命名、设备的保护以及设备的分配与释放等，同时为设备管理和数据传送提供必要的存储空间。
 - **设备驱动程序：**与硬件直接相关，负责具体实现系统对设备发出的操作指令，驱动I/O设备工作的驱动程序。
 - 中断处理程序：用于保存被中断进程的 CPU 环境，转入相应的中断处理程序进行处理，处理完后再恢复被中断进程的现场后返回到被中断进程。

## SPOOLing技术

![image-20240613164300511](D:\MarkDown\assets\image-20240613164300511.png)

![image-20240613164305433](D:\MarkDown\assets\image-20240613164305433.png)

![image-20240613164312923](D:\MarkDown\assets\image-20240613164312923.png)

![image-20240613164326738](D:\MarkDown\assets\image-20240613164326738.png)![image-20240613164333484](D:\MarkDown\assets\image-20240613164333484.png)![image-20240613164339711](D:\MarkDown\assets\image-20240613164339711.png)![image-20240613164358984](D:\MarkDown\assets\image-20240613164358984.png)

## RAID的各个级别及优缺点

RAID大幅度不仅增加了磁盘的容量，而且极大地提高了磁盘的I/O速度和整个磁盘系统的可靠性。

- **RAID0级：**仅提供了并行交叉存取
  能够实现高效传输和高速的I/O请求，但无冗余校验功能，使磁盘系统可靠性不高，较少使用。
- **RAID1级：**具有磁盘镜像功能可靠性好，从故障中恢复简单；但磁盘容量的利用率只有50%。
- **RAID3级：**具有并行传输功能只利用一台奇偶校验盘来完成数据校验。
- **RAID5级：**具有独立传送功能每个驱动器有各自独立的数据通路，独立进行读/写，无专门的校验
  盘，校验信息螺旋方式散布在所有数据盘上。
- **RAID6级和RAID7级：**RAID6具有独立的数据访问通路，比RAID3和RAID5性能好，但改进有限，价格昂贵；RAID7是RAID6的改进，具有较高的传输速率和优异的性能，是目前最高档次的磁盘阵列，价格也比较高。

## 磁盘访问时间组成

磁盘设备在工作时以恒定速率旋转。为了读或写，磁头移动到所要求的磁道上， 并等待所要求的扇区的开始位置旋转到磁头下，然后再开始读或写数据

- 寻道时间 Ts：把磁臂(磁头)移动到指定磁道上所经历的时间，时间是启动磁臂的时间 s 与磁头移动 n 条磁道所花费的时间之和。$T_s=m\times n+s$
- 旋转延迟时间 Tr：指定扇区移动到磁头下面所经历的时间。
- 传输时间 Tt：指把数据从磁盘读出或向磁盘写入数据所经历的时间。Tt的大小与每次所读/写的字节数 b 和旋转速度有关:$T_t=\frac b {rN}$
- 访问总时间 Tt：$T_a=T_s+\frac 1 {2r}+\frac b {rN}$

## 磁盘空闲空间表示方法

- **空闲表法**
  - 空闲表法属于连续分配方式，它与内存的动态分配方式雷同，它为每个文件分配一块连续的存储空间。即系统也为外存上的空闲区建立一张空闲表，每个空闲区对应于一个空闲表项，其中包括表项序号、该空闲区的第一个盘块号、该区的空闲盘块数等信息。再将所有空闲区按其起始盘块号递增的次序排列，形成空闲盘块表。
  - ![image-20240613114202503](D:\MarkDown\assets\image-20240613114202503.png)
- **空闲链表法**
  - 空闲链表法是将所有空闲盘区拉成一条空闲链。根据构成链所用基本元素不同，分为空闲盘块链和空闲盘区链：
  - ![image-20240613114307954](D:\MarkDown\assets\image-20240613114307954.png)
  - **空闲盘块链**
    - 将磁盘上的所有空闲空间以盘块为单位拉成一条链，其中的每一个盘块都有指向后继盘块的指针。
    - 用户请求分配存储空间时，系统从链首开始，依次摘下适当数目的空间盘块分配给用户；当用户释放存储空间时，系统将回收的盘块依次挂在空闲盘块链的末尾。
    - 优点在于用于分配和回收一个盘块的过程非常简单，但在为一个文件分配盘块时，可能要重复操作多次，分配和回收的效率较低；相应的空闲盘块链会很长。
  - **空闲盘区链**
    - 将磁盘上的所有空闲盘区（每个盘区可包含若干个盘块）拉成一条链。
    - 分配盘区的方法与内存的动态分区分配类似，通常采用首次适应算法；在回收盘区时，同样也要将回收区域相邻接的空闲盘区相合并。
    - 分配与回收的过程比较复杂，但分配和回收的效率可能较高，每次为文件分配多个连续的块，且空闲盘区链较短。

## 磁盘调度算法

**==先来先服务（FCFS）==**

- 按访问请求到达的先后次序服务
- 优点：简单，公平；
- 缺点：效率不高，相邻两次请求可能会造成最内到最外的柱面寻道，使磁头反复移动，增加了服务时间，对机械也不利
- ![image-20240613114950253](D:\MarkDown\assets\image-20240613114950253.png)

**==最短寻道时间优先（SSTF）==**

- 优先选择距当前磁头最近的访问请求进行服务，主要考虑寻道优先
- 优点：改善了磁盘平均服务时间；
- 缺点：造成某些访问请求长期等待得不到服务
- ![image-20240613115040329](D:\MarkDown\assets\image-20240613115040329.png)

**==扫描算法（电梯算法）（SCAN）==**

- 克服最短寻道优先的缺点:距离+方向
- 方法：当设备无访问请求时，磁头不动；当有访问请求时，磁头按一个方向移动，在移动过程中对遇
  到的访问请求进行服务，然后判断该方向上是否还有访问请求，如果有则继续扫描；否则改变移动方
  向，并为经过的访问请求服务，如此反复
- ![image-20240613115129899](D:\MarkDown\assets\image-20240613115129899.png)

**==循环扫描调度算法（CSCAN）==**

- 问题：电梯算法杜绝了饥饿，但当请求对磁道的分布是均匀时，磁头回头，近磁头端的请求很少（因为磁头刚经过），而远端请求较多，这些请求等待时间要长一些。
- 方法：总是从0号柱面开始向里扫描。移动臂到达最后个一个柱面后，立即带动读写磁头快速返回到0号柱面。返回时不为任何的等待访问者服务。返回后可再次进行扫描。
- ![image-20240613115251107](D:\MarkDown\assets\image-20240613115251107.png)

**N-Step-SCAN算法**

- SSTF、SCAN、CSCAN几种调度算法都可能出现磁臂停留在某处不动的情况，称为磁臂粘着(Arm-Stickiness)。在高密度盘上更容易出现此情况。
- N-STEP-SCAN算法将磁盘请求队列分成若干个长度为N的子队列。磁盘调度将按FCFS算法依次处理这些子队列。而每处理一个队列时，又是按SCAN算法。这样就可避免出现粘着现象。

**FSCAN算法**

- 本算法是N步SCAN算法的简化。它只将磁盘请求访问队列分成两个子队列：
- 当前所有请求磁盘I／O的进程形成的队列，由磁盘调度按SCAN算法进行处理。
- 在扫描期间，新出现的所有请求磁盘I／O进程组成的等待处理的请求队列。从而使所有的新请求都将被推迟到下一次扫描时处理。

**调度算法的选择**

- 实际系统相当普遍采用最短寻道时间优先算法，因为它简单有效，性价比好。
- 扫描算法更适于磁盘负担重的系统。
- 磁盘负担很轻的系统也可以采用先来先服务算法
- 一般要将磁盘调度算法作为操作系统的单独模块编写，利于修改和更换。

## 外存的组织方式

![image-20240613120107306](D:\MarkDown\assets\image-20240613120107306.png)

==**连续分配**==

- 每个文件在磁盘上占有一组连续块
- ![image-20240613120319115](D:\MarkDown\assets\image-20240613120319115.png)
- 优势
  - 首先，简单、容易实现，记录每个文件用到的磁盘块简化为只需记住一个数字即可，也就是第一块的磁盘地址。
  - 其次，性能较好，在一次操作中，就可以从磁盘上读出整个文件。
- 缺点：不能预知文件的长度，会造成磁盘碎片；紧凑可以解决碎片，但代价大。
- 适用于CD-ROM，文件长度已知且在使用中不会改变。

==**链表分配**==

- 为每个文件构造磁盘块的链表；每个块的第一个字作为指向下一块的指针，块的其他部分存放数据。
- 优点：该方法可以利用每个磁盘块。不会因为磁盘碎片而浪费存储空间。
- 缺点
  - 顺序读取文件非常方便，但是随机存取却相当缓慢。
  - 指针会占据一定的字节，磁盘块可用字节数不再是2的整数次幂。
- 隐式链接
  ![image-20240613162859042](D:\MarkDown\assets\image-20240613162859042.png)
- 显式链接
  ![image-20240613162937902](D:\MarkDown\assets\image-20240613162937902.png)
- 索引分配

  - 属于离散分配方式
  - 每个文件一张索引表，记录逻辑块与物理块的对应关系，支持**随机访问**
  - 存放索引表的块：索引块
  - 存放数据的块：数据块

  ![image-20240613163102389](D:\MarkDown\assets\image-20240613163102389.png)

  - 链接方案：索引表太长，拆分成多个索引块，将索引表离散存储在多个索引块（磁盘块中），这些索引块通过链接方式组织。
  - 多级索引：采用多级索引结构（与多级页表类似）若采用K级索引，需要K+1次磁盘I/O操作；
  - 混合索引：多种索引方式结合，如同时包含直接地址索引，一级间接索引（单级索引），两级间接索引等
  - 小结
    ![image-20240613163420170](D:\MarkDown\assets\image-20240613163420170.png)

## 文件系统的存储分配的方法

## 文件系统索引分配方式的空间占用
